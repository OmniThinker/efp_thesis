{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd733f89-3857-49ae-8679-a9150b0991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e9ef169-8b98-4ba8-a0d0-f84b3daed4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(os.getcwd()), \"..\"))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorWithPadding\n",
    ")\n",
    "import torch.nn as nn\n",
    "from certainty import (\n",
    "    load_file, load_events, seed_everything, CACHE_DIR, RANDOM_SEED)\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c3fa9b9-c9fd-422a-95db-896508a7967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/peder/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Thu Mar  7 10:47:46 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "seqeval = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "86587bf6-159e-4116-8f70-1e8724884d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_file('en_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "67539f4e-e7d2-4df7-a7e7-97a27c556b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased', local_only=True, cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "6e4da369-e9c6-4df1-93c9-a7b9dcff20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for sample in data:\n",
    "    prefix = \"Label event triggers: \"\n",
    "    sample['text'] = prefix + sample['text']\n",
    "    sample['prefix_len'] = len(prefix)\n",
    "    enc = tokenizer(sample['text'], add_special_tokens=False, padding='max_length', truncation=True, max_length=256, return_offsets_mapping=True)\n",
    "    sample = {**enc, **sample}\n",
    "    labels = [0 if (0, 0) != offset else -100 for offset in sample['offset_mapping']]\n",
    "    events = sample['events']\n",
    "    prefix_len = sample['prefix_len']\n",
    "    \n",
    "    trigger = []\n",
    "    \n",
    "    for event in events:\n",
    "        for i, offset in enumerate(sample['offset_mapping']):\n",
    "            span = event['trigger'][1][0]\n",
    "            (start, end) = map(int, span.split(\":\"))\n",
    "            start += prefix_len\n",
    "            end += prefix_len\n",
    "            if start == offset[0]:\n",
    "                labels[i] = 1\n",
    "                trigger = [i]\n",
    "            elif start <= offset[0] and end >= offset[1]:\n",
    "                labels[i] = 2\n",
    "                trigger.append(i)\n",
    "            else:\n",
    "                if (trigger):\n",
    "                    event['decoded_trigger'] = tokenizer.decode(sample['input_ids'][trigger[0]:trigger[-1]+1])\n",
    "                trigger = []\n",
    "                \n",
    "    sample['labels'] = labels\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5fecd348-7ff4-427b-a9b4-7cd4ec828b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"O\", \"B-trigger\", \"I-trigger\"]\n",
    "\n",
    "label2id_trigger = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label_trigger = {v: k for k, v in label2id_trigger.items()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "10594bc8-d4cb-4126-be10-2f29b42cac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = []\n",
    "for sample in samples:\n",
    "    sample = {key: sample[key] for key in ['input_ids', 'attention_mask', 'labels']}\n",
    "    encoded.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9717c382-dbec-46b9-9af1-5ac3eac7d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Dataset.from_list(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f5a6d06c-9e92-4609-9075-a50e4219122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 6751\n",
       "})"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d840b553-0fce-4906-8fff-dc5ee3692b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_trigger(eval_pred):\n",
    "    preds, label_ids = eval_pred\n",
    "    prediction_ids = np.argmax(preds, axis=2)\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    for label_seq, pred_seq in zip(label_ids, prediction_ids):\n",
    "        pred_row = []\n",
    "        label_row = []\n",
    "        for l, p in zip(label_seq, pred_seq):\n",
    "            if l != -100:\n",
    "                pred_row.append(id2label_trigger[p])\n",
    "                label_row.append(id2label_trigger[l])\n",
    "        pred_labels.append(pred_row)\n",
    "        true_labels.append(label_row)\n",
    "\n",
    "    results = seqeval.compute(predictions=pred_labels, references=true_labels)['trigger']\n",
    "    return {\"trigger_f1\": results['f1'],\n",
    "            \"trigger_precision\": results['precision'],\n",
    "            \"trigger_recall\": results['recall']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e7053c9b-3b19-4f97-9fae-aa14bb47b2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_56322/2382871199.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_trigger = Trainer(\n"
     ]
    }
   ],
   "source": [
    "model_trigger = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=3, id2label=id2label_trigger, label2id=label2id_trigger\n",
    ")\n",
    "\n",
    "training_args_trigger = TrainingArguments(\n",
    "    output_dir=\"../models/trigger\" + str(42),\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    lr_scheduler_type='reduce_lr_on_plateau',\n",
    "    learning_rate=0.00005,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer_trigger = Trainer(\n",
    "    model=model_trigger,\n",
    "    args=training_args_trigger,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=train_set,\n",
    "    compute_metrics=compute_metrics_trigger,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]  # Stop after 3 epochs without improvement\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c4174394-b558-49a0-b6af-83b792848fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2110' max='2110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2110/2110 1:17:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Trigger F1</th>\n",
       "      <th>Trigger Precision</th>\n",
       "      <th>Trigger Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.072840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.061171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.051513</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.006395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.043078</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.036878</td>\n",
       "      <td>0.033308</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.017186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.032217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.054484</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.028777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.026402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>0.085756</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.047162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.023620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peder/.pyenv/versions/3.10.13/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/peder/.pyenv/versions/3.10.13/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/peder/.pyenv/versions/3.10.13/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/peder/.pyenv/versions/3.10.13/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/peder/.pyenv/versions/3.10.13/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2110, training_loss=0.04668721971918621, metrics={'train_runtime': 4652.0169, 'train_samples_per_second': 14.512, 'train_steps_per_second': 0.454, 'total_flos': 4410275133312000.0, 'train_loss': 0.04668721971918621, 'epoch': 10.0})"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_trigger.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ca95f-dc11-458d-83a4-2b333eb762b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
