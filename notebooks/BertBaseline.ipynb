{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8bb39b-7a23-4afb-ae53-8812caf5089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9809a4-2316-4add-8f39-8bc3de20a295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 09:23:21.265690: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-12 09:23:21.405355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-12 09:23:22.393282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from typing import List, Sequence, Iterator, Generator, Tuple\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85421c72-aa35-4316-9de1-47d822d98cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834e723d-42d6-4663-b9b7-5b5b88bd0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.abspath(os.getcwd()), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5715a508-787b-4bb5-a473-e9d7dae8128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from certainty import EventSentence, EventType, load_events, id2label, label2id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b31188f-cf18-4b78-a4be-b87ffac66af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events, dev_events, test_events = load_events('en_train.json', 'en_dev.json', 'en_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867ba385-c7ab-4823-bd82-058c72f69450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c00fa871-a626-4cbc-b336-19a4b1466d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'trigger', 'type', 'genericity', 'polarity'],\n",
       "    num_rows: 4261\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_pandas(pd.DataFrame(train_events)[[\"label\", \"text\", \"trigger\", \"type\", \"genericity\", \"polarity\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f755a3c9-07f9-427d-8b60-d50ac4626a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "cannot mix list and non-list, non-null values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_events\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/datasets/arrow_dataset.py:952\u001b[0m, in \u001b[0;36mDataset.from_list\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# for simplicity and consistency wrt OptimizedTypedSequence we do not use InMemoryTable.from_pylist here\u001b[39;00m\n\u001b[1;32m    951\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {k: [r\u001b[38;5;241m.\u001b[39mget(k) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m mapping] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mapping[\u001b[38;5;241m0\u001b[39m]} \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/datasets/arrow_dataset.py:912\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    910\u001b[0m     arrow_typed_mapping[col] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    911\u001b[0m mapping \u001b[38;5;241m=\u001b[39m arrow_typed_mapping\n\u001b[0;32m--> 912\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/datasets/table.py:758\u001b[0m, in \u001b[0;36mInMemoryTable.from_pydict\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pydict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    744\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    Construct a Table from Arrow arrays or columns.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m        `datasets.table.Table`\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/table.pxi:1813\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular.from_pydict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/table.pxi:5339\u001b[0m, in \u001b[0;36mpyarrow.lib._from_pydict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/array.pxi:374\u001b[0m, in \u001b[0;36mpyarrow.lib.asarray\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/array.pxi:248\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/array.pxi:113\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/datasets/arrow_writer.py:191\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     trying_cast_to_python_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrying_int_optimization:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/array.pxi:344\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/array.pxi:42\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: cannot mix list and non-list, non-null values"
     ]
    }
   ],
   "source": [
    "trainset = Dataset.from_list(train_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f9d2db-77bf-4c9c-ac64-2ff7083d082f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent_id': 'bc/CNN_IP_20030329.1600.02/001',\n",
       " 'text': 'It was in northern Iraq today that an eight artillery round hit the site occupied by Kurdish fighters near Chamchamal',\n",
       " 'type': 'Attack',\n",
       " 'modality': 'Asserted',\n",
       " 'label': 1,\n",
       " 'polarity': 'Positive',\n",
       " 'genericity': 'Specific',\n",
       " 'trigger': 'hit'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4f35e3-0aef-4041-be79-47c223da0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset: Dataset = Dataset.from_list(train_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7656d74-f7d3-43ac-90b4-429f083ffe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "devset: Dataset = Dataset.from_list(dev_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1960821d-34c0-4421-af07-0f47fa270160",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset: Dataset = Dataset.from_list(test_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6683da-65d4-4f6f-b1e5-360d56aa7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased', cache_dir=\"../cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd60641-5251-48b6-9a69-e3b03f4f4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(data: Dataset):\n",
    "    return tokenizer(data[\"features\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ffdc958-c663-475e-ab93-9d56800653ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d293e8a-df57-4c2b-b5ab-dc62b9317144",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24fc4ed1-b259-4b2b-9619-72c57ff7bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "            \"precision\":precision.compute(predictions=predictions, references=labels)[\"precision\"], \n",
    "            \"recall\":recall.compute(predictions=predictions, references=labels)[\"recall\"], \n",
    "            \"f1\":f1.compute(predictions=predictions, references=labels)[\"f1\"], \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0486d74d-ff80-4e0e-9012-97949a380278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebb71adcbb645fcb98ec20bb0ca7f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8035e74c62054bfa8fa8da8ff2503285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95027dbcfac4fe3a4d18116245e4bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/496 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67e086eafec43f0a54c293a661fa39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/496 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4de3467dea40bc9baccfe9f3f6e2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315d22b44ffd4dc695ab42647ee6e813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeder-august\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../wandb/run-20250124_104745-06osapdb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peder-august/certainty/runs/06osapdb' target=\"_blank\">bert-baseline-using-trigger</a></strong> to <a href='https://wandb.ai/peder-august/certainty' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peder-august/certainty' target=\"_blank\">https://wandb.ai/peder-august/certainty</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peder-august/certainty/runs/06osapdb' target=\"_blank\">https://wandb.ai/peder-august/certainty/runs/06osapdb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peder/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='534' max='534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [534/534 00:59, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.444957</td>\n",
       "      <td>0.792339</td>\n",
       "      <td>0.813896</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.864295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>0.434821</td>\n",
       "      <td>0.816532</td>\n",
       "      <td>0.865014</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.873435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626bb0509223476e87c16dca91c95caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█</td></tr><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/precision</td><td>▁█</td></tr><tr><td>eval/recall</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▇██</td></tr><tr><td>train/global_step</td><td>▁▇██</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81653</td></tr><tr><td>eval/f1</td><td>0.87344</td></tr><tr><td>eval/loss</td><td>0.43482</td></tr><tr><td>eval/precision</td><td>0.86501</td></tr><tr><td>eval/recall</td><td>0.88202</td></tr><tr><td>eval/runtime</td><td>0.8977</td></tr><tr><td>eval/samples_per_second</td><td>552.506</td></tr><tr><td>eval/steps_per_second</td><td>34.532</td></tr><tr><td>total_flos</td><td>154235517900768.0</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>534</td></tr><tr><td>train/grad_norm</td><td>6.64402</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3849</td></tr><tr><td>train_loss</td><td>0.38102</td></tr><tr><td>train_runtime</td><td>60.6091</td></tr><tr><td>train_samples_per_second</td><td>140.606</td></tr><tr><td>train_steps_per_second</td><td>8.811</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-baseline-using-trigger</strong> at: <a href='https://wandb.ai/peder-august/certainty/runs/06osapdb' target=\"_blank\">https://wandb.ai/peder-august/certainty/runs/06osapdb</a><br/> View project at: <a href='https://wandb.ai/peder-august/certainty' target=\"_blank\">https://wandb.ai/peder-august/certainty</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../wandb/run-20250124_104745-06osapdb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def concat_trigger(data: Dataset):\n",
    "    data[\"features\"] = data[\"trigger\"] + \" \" + data[\"text\"]\n",
    "    return data\n",
    "    \n",
    "tokenized_train: Dataset = trainset.map(concat_trigger, batched=False).map(preprocess_function, batched=True)\n",
    "tokenized_dev: Dataset = devset.map(concat_trigger, batched=False).map(preprocess_function, batched=True)\n",
    "tokenized_test: Dataset = testset.map(concat_trigger, batched=False).map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", cache_dir=\"../cache\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"certainty\",\n",
    "    name=\"bert-baseline-using-trigger\",\n",
    "    dir=\"..\",\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/bert_baseline\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "383a5a8f-f1bc-4daf-827a-82b5edf3897d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bc5067363c48ff9a5e4f9d7627937f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635b9d1e64b74fb5bfbf0bfd0082e44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cf41bdc429418f95cfbcddff716912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/496 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07ecc9deaf84915af6212409208db42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/496 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce8e57cfd824c2884d5874117df4ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1f13e25a334af889077d4a75846ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeder-august\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../wandb/run-20250124_122054-ichqvhnt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peder-august/certainty/runs/ichqvhnt' target=\"_blank\">bert-baseline-using-event-type</a></strong> to <a href='https://wandb.ai/peder-august/certainty' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peder-august/certainty' target=\"_blank\">https://wandb.ai/peder-august/certainty</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peder-august/certainty/runs/ichqvhnt' target=\"_blank\">https://wandb.ai/peder-august/certainty/runs/ichqvhnt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peder/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='534' max='534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [534/534 01:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.475227</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.793269</td>\n",
       "      <td>0.926966</td>\n",
       "      <td>0.854922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.469655</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.836898</td>\n",
       "      <td>0.879213</td>\n",
       "      <td>0.857534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d2b4495c3345f199621c414b6a6a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█</td></tr><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/precision</td><td>▁█</td></tr><tr><td>eval/recall</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▇██</td></tr><tr><td>train/global_step</td><td>▁▇██</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.79032</td></tr><tr><td>eval/f1</td><td>0.85753</td></tr><tr><td>eval/loss</td><td>0.46965</td></tr><tr><td>eval/precision</td><td>0.8369</td></tr><tr><td>eval/recall</td><td>0.87921</td></tr><tr><td>eval/runtime</td><td>0.942</td></tr><tr><td>eval/samples_per_second</td><td>526.554</td></tr><tr><td>eval/steps_per_second</td><td>32.91</td></tr><tr><td>total_flos</td><td>155373909607968.0</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>534</td></tr><tr><td>train/grad_norm</td><td>5.02955</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4002</td></tr><tr><td>train_loss</td><td>0.39662</td></tr><tr><td>train_runtime</td><td>62.6461</td></tr><tr><td>train_samples_per_second</td><td>136.034</td></tr><tr><td>train_steps_per_second</td><td>8.524</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-baseline-using-event-type</strong> at: <a href='https://wandb.ai/peder-august/certainty/runs/ichqvhnt' target=\"_blank\">https://wandb.ai/peder-august/certainty/runs/ichqvhnt</a><br/> View project at: <a href='https://wandb.ai/peder-august/certainty' target=\"_blank\">https://wandb.ai/peder-august/certainty</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../wandb/run-20250124_122054-ichqvhnt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def concat_event_type(data: Dataset):\n",
    "    data[\"features\"] = data[\"type\"] + \" \" + data[\"text\"]\n",
    "    return data\n",
    "    \n",
    "tokenized_train: Dataset = trainset.map(concat_event_type, batched=False).map(preprocess_function, batched=True)\n",
    "tokenized_dev: Dataset = devset.map(concat_event_type, batched=False).map(preprocess_function, batched=True)\n",
    "tokenized_test: Dataset = testset.map(concat_event_type, batched=False).map(preprocess_function, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", cache_dir=\"../cache\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"certainty\",\n",
    "    name=\"bert-baseline-using-event-type\",\n",
    "    dir=\"..\",\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/bert_baseline\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfdb64-1582-4842-96f5-b2a5cf46e9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
